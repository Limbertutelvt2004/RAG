## ğŸ§  RAG Chatbot (LangChain + Streamlit + FAISS)

- A Retrieval-Augmented Generation (RAG) chatbot built with LangChain, Streamlit, and FAISS, designed to answer questions accurately from custom documents (PDFs).
- The system adapts responses based on the userâ€™s experience level and runs fully offline using local LLMs via Ollama.

---

## âœ¨ Features

- ğŸ“„ PDF Knowledge Ingestion
  - Load and process custom PDF documents

- âœ‚ï¸ Smart Text Chunking
  - Recursive splitting for optimal retrieval

- ğŸ§  Semantic Search with FAISS
  - Fast vector similarity search using embeddings

- ğŸ¯ Experience-Aware Answers
  - Adapts explanation depth (Beginner / Intermediate / Advanced)

- ğŸ’¬ Interactive Chat UI
  - Built with Streamlit for a clean, responsive interface

- ğŸ”’ Offline & Private
  - Uses local LLMs (no data sent to cloud APIs)

---

## ğŸ—ï¸ Tech Stack

| Component       | Technology                  |
| --------------- | --------------------------- |
| Language        | Python                      |
| UI              | Streamlit                   |
| RAG Framework   | LangChain                   |
| Vector Database | FAISS                       |
| Embeddings      | Sentence Transformers       |
| LLM Backend     | Ollama (LLaMA / Phi / etc.) |

---

## ğŸ“‚ Project Structure

```powershell
RAG/
â”œâ”€â”€ app.py               # Streamlit UI
â”œâ”€â”€ ingest.py            # PDF ingestion & vectorization
â”œâ”€â”€ rag_pipeline.py      # RAG retrieval + generation logic
â”œâ”€â”€ user_profile.py      # User experience handling
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ data/
â”‚   â””â”€â”€ docs/            # Input PDFs
â””â”€â”€ vectorstore/         # FAISS index (generated, ignored in git)
```

---

## ğŸš€ Getting Started

#### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/your-repo-name.git
cd RAG
```

#### 2ï¸âƒ£ Create & Activate Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate   # Windows
```

#### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

#### 4ï¸âƒ£ Add Your PDFs

Place your documents inside:
```bash
data/docs/
```

#### 5ï¸âƒ£ Ingest Documents
```bash
python ingest.py
```

This generates vector embeddings and stores them in FAISS.

#### 6ï¸âƒ£ Run the Chatbot
```bash
streamlit run app.py
```

#### Access the app at:
```arduino
http://localhost:8501
```

#### ğŸ§  Supported LLMs (via Ollama)

- `llama3`
- `phi3`

- Any locally supported Ollama model

> Make sure Ollama is running:
```bash
ollama serve
```

---

### âš ï¸ Notes

- The vectorstore/ directory is not committed (generated data)
- Virtual environments are ignored using .gitignore
- Designed for learning, experimentation, and portfolio projects

---

### ğŸ¯ Use Cases

- ğŸ“š Study assistants
- ğŸ§ª Research paper Q&A
- ğŸ¢ Internal documentation bots

---

### ğŸ‘¨â€ğŸ’» Developer knowledge bases

- ğŸ“Œ Future Enhancements
- Chat history memory
- Multi-document support
- Web-based deployment (API-based LLMs)
- User authentication
- RAG evaluation metrics

---

### ğŸ¤ Contributing

Pull requests and suggestions are welcome.
Feel free to fork and experiment.

---

## ğŸ‘¨â€ğŸ’» Author

### Vinaal R

Passionate Learner | Aspiring Developer | Python Enthusiast

### Contact me through 

[![LinkedIn](https://img.shields.io/badge/LinkedIn-%230077B5.svg?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/vinaal/) [![GitHub](https://img.shields.io/badge/GitHub-%23181717.svg?logo=github&logoColor=white)](https://github.com/Dark-Vinaal) 

<a href="https://vinaalr.netlify.app/">
  <img src="https://img.shields.io/badge/VR%20-%20Portfolio-d5d5d5?style=for-the-badge&labelColor=0A0209&color=d5d5d5&logoColor=0A0209" />
</a>

---

### â­ If you like this project

> Give it a â­ on GitHub â€” it helps a lot!

---